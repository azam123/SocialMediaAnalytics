{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8780064c",
   "metadata": {},
   "source": [
    "# Social Media Analytics — Prediction Engine Notebook\n",
    "\n",
    "This notebook demonstrates how to generate synthetic data, train machine learning models to predict social media engagement metrics (reach, likes, engagement rate), and implement a simple AI assistant for hashtag and description generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de11a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Title & imports\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import joblib\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "print(\"Imports ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: generate synthetic dataset\n",
    "def generate_synthetic_data(n=6000, seed=RANDOM_SEED):\n",
    "    np.random.seed(seed)\n",
    "    d = {}\n",
    "    d['user_followers'] = np.random.randint(50, 500000, size=n)\n",
    "    d['user_avg_engagement_rate'] = np.random.beta(2, 50, size=n)\n",
    "    d['media_type'] = np.random.choice(['none', 'image', 'video'], size=n, p=[0.3, 0.5, 0.2])\n",
    "    d['num_media_items'] = np.random.poisson(1, size=n)\n",
    "    d['post_text_len'] = np.random.randint(5, 800, size=n)\n",
    "    d['num_hashtags'] = np.random.poisson(2, size=n)\n",
    "    d['num_mentions'] = np.random.poisson(0.3, size=n)\n",
    "    d['num_emojis'] = np.random.poisson(1, size=n)\n",
    "    d['has_link'] = np.random.binomial(1, 0.15, size=n)\n",
    "    d['hour'] = np.random.randint(0, 24, size=n)\n",
    "    d['day_of_week'] = np.random.randint(0, 7, size=n)\n",
    "    df = pd.DataFrame(d)\n",
    "    media_boost = df['media_type'].map({'none': 0.6, 'image': 1.0, 'video': 1.6})\n",
    "    time_boost = np.where((df['hour'] >= 18) & (df['hour'] <= 22), 1.2, 1.0)\n",
    "    base_reach = df['user_followers'] * (0.02 + 0.2 * df['user_avg_engagement_rate'])\n",
    "    df['reach'] = (base_reach * media_boost * time_boost * (1 + 0.05 * df['num_hashtags'])).clip(min=5)\n",
    "    df['reach'] = (df['reach'] * (1 + 0.5 * np.random.randn(n))).clip(min=5).round().astype(int)\n",
    "    df['engagement_rate'] = (df['user_avg_engagement_rate'] * (0.8 + 0.6 * np.random.rand(n))).round(4)\n",
    "    df['likes'] = (df['reach'] * df['engagement_rate'] * (0.2 + 0.8 * np.random.rand(n))).clip(min=0).round().astype(int)\n",
    "    return df\n",
    "\n",
    "df = generate_synthetic_data(6000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f754085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Feature engineering\n",
    "df_feat = df.copy()\n",
    "df_feat['daypart'] = pd.cut(df_feat['hour'], bins=[-1,5,11,17,22,24], labels=['late_night','morning','afternoon','evening','late_night2'])\n",
    "df_feat['media_type'] = df_feat['media_type'].astype(str)\n",
    "df_feat['daypart'] = df_feat['daypart'].astype(str)\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    'user_followers','user_avg_engagement_rate','post_text_len','num_hashtags',\n",
    "    'num_mentions','num_emojis','has_link','media_type','daypart','day_of_week'\n",
    "]\n",
    "\n",
    "X = df_feat[FEATURE_COLS]\n",
    "y_reach = df_feat['reach']\n",
    "y_likes = df_feat['likes']\n",
    "y_eng = df_feat['engagement_rate']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543eb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train models\n",
    "numeric_features = ['user_followers','user_avg_engagement_rate','post_text_len','num_hashtags','num_mentions','num_emojis','has_link']\n",
    "cat_features = ['media_type','daypart','day_of_week']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', 'passthrough', numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "])\n",
    "\n",
    "# Train reach model\n",
    "model_reach = make_pipeline(preprocessor, GradientBoostingRegressor(random_state=RANDOM_SEED, n_estimators=150, max_depth=4))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_reach, test_size=0.2, random_state=RANDOM_SEED)\n",
    "model_reach.fit(X_train, y_train)\n",
    "pred = model_reach.predict(X_test)\n",
    "print('Reach RMSE:', math.sqrt(mean_squared_error(y_test, pred)))\n",
    "print('Reach R2:', r2_score(y_test, pred))\n",
    "joblib.dump(model_reach, 'models/gbm_reach.joblib')\n",
    "\n",
    "# Train likes model\n",
    "model_likes = make_pipeline(preprocessor, GradientBoostingRegressor(random_state=RANDOM_SEED, n_estimators=150, max_depth=4))\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y_likes, test_size=0.2, random_state=RANDOM_SEED)\n",
    "model_likes.fit(X_train2, y_train2)\n",
    "pred_l = model_likes.predict(X_test2)\n",
    "print('Likes RMSE:', math.sqrt(mean_squared_error(y_test2, pred_l)))\n",
    "print('Likes R2:', r2_score(y_test2, pred_l))\n",
    "joblib.dump(model_likes, 'models/gbm_likes.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Hashtag and description suggester\n",
    "STOPWORDS = set(_stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "def suggest_hashtags_from_text(text, top_k=5):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return []\n",
    "    tokens = re.findall(r\"\\w+\", text.lower())\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS and len(t) > 2]\n",
    "    if not tokens:\n",
    "        return []\n",
    "    freq = pd.Series(tokens).value_counts()\n",
    "    top = list(freq.head(top_k).index)\n",
    "    return ['#' + t for t in top]\n",
    "\n",
    "def suggest_description_for_media(text, max_words=25):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return ''\n",
    "    words = text.strip().split()\n",
    "    preview = ' '.join(words[:max_words])\n",
    "    suffix = '...' if len(words) > max_words else ''\n",
    "    return (preview + suffix).strip()\n",
    "\n",
    "example_text = \"Launching our new summer collection — lightweight jackets, breathable fabric, and bold colors! Shop now: https://example.com\"\n",
    "print('Hashtags:', suggest_hashtags_from_text(example_text, top_k=6))\n",
    "print('Description:', suggest_description_for_media(example_text, max_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Inference wrapper\n",
    "model_reach = joblib.load('models/gbm_reach.joblib')\n",
    "model_likes = joblib.load('models/gbm_likes.joblib')\n",
    "\n",
    "def prepare_features_from_payload(payload):\n",
    "    post_text = payload.get('post_text', '') or ''\n",
    "    media_type = payload.get('media_type', 'none')\n",
    "    num_media_items = int(payload.get('num_media_items', 0))\n",
    "    scheduled_time = payload.get('scheduled_time', None)\n",
    "    dt = pd.to_datetime(scheduled_time) if scheduled_time else pd.to_datetime(datetime.utcnow())\n",
    "    hour = int(dt.hour)\n",
    "    day_of_week = int(dt.dayofweek)\n",
    "    user_followers = int(payload.get('user_followers', 100))\n",
    "    user_avg_engagement_rate = float(payload.get('user_avg_engagement_rate', 0.01))\n",
    "    features = {\n",
    "        'user_followers': user_followers,\n",
    "        'user_avg_engagement_rate': user_avg_engagement_rate,\n",
    "        'post_text_len': len(post_text),\n",
    "        'num_hashtags': int(payload.get('num_hashtags', 0)),\n",
    "        'num_mentions': int(payload.get('num_mentions', 0)),\n",
    "        'num_emojis': int(payload.get('num_emojis', 0)),\n",
    "        'has_link': 1 if ('http' in post_text or 'www.' in post_text) else 0,\n",
    "        'media_type': media_type,\n",
    "        'daypart': pd.cut([hour], bins=[-1,5,11,17,22,24], labels=['late_night','morning','afternoon','evening','late_night2'])[0],\n",
    "        'day_of_week': day_of_week\n",
    "    }\n",
    "    return pd.DataFrame([features])\n",
    "\n",
    "def inference(payload):\n",
    "    suggested_hashtags = suggest_hashtags_from_text(payload.get('post_text',''), top_k=6)\n",
    "    suggested_description = None\n",
    "    if payload.get('media_type') in ('image','video'):\n",
    "        suggested_description = suggest_description_for_media(payload.get('post_text',''), max_words=25)\n",
    "    feat_payload = payload.copy()\n",
    "    feat_payload['num_hashtags'] = len(suggested_hashtags)\n",
    "    feat_df = prepare_features_from_payload(feat_payload)\n",
    "    pred_reach = int(max(0, round(float(model_reach.predict(feat_df)[0]))))\n",
    "    pred_likes = int(max(0, round(float(model_likes.predict(feat_df)[0]))))\n",
    "    pred_eng_rate = round(pred_likes / pred_reach if pred_reach > 0 else 0.0, 4)\n",
    "    explanations = {'top_features': ['user_followers','media_type','daypart','num_hashtags']}\n",
    "    return {\n",
    "        'suggested_hashtags': suggested_hashtags,\n",
    "        'suggested_description': suggested_description,\n",
    "        'predicted_reach': pred_reach,\n",
    "        'predicted_likes': pred_likes,\n",
    "        'predicted_engagement_rate': pred_eng_rate,\n",
    "        'explanations': explanations\n",
    "    }\n",
    "\n",
    "payload_example = {\n",
    "    \"post_text\": \"Announcing our biggest sale of the year! 50% off on selected items. Free shipping for orders over $50. Grab yours now!\",\n",
    "    \"media_type\": \"image\",\n",
    "    \"num_media_items\": 1,\n",
    "    \"scheduled_time\": \"2025-07-15T19:30:00Z\",\n",
    "    \"user_followers\": 12500,\n",
    "    \"user_avg_engagement_rate\": 0.012\n",
    "}\n",
    "print('Inference result:', inference(payload_example))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
